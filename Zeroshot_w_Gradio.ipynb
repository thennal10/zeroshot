{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thennal10/zeroshot/blob/main/Zeroshot_w_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot and few-shot TTS using YourTTS and Gradio\n",
        "A quick demo of the abilities of YourTTS using Gradio. Run the setup code blocks, and then run **either** the 'Synthesize from d-vectors' or the 'Finetune and Synthesize' blocks. Click on the link that the last cell outputs.\n",
        "\n",
        "Make sure to change your runtime to GPU if you're doing finetuning."
      ],
      "metadata": {
        "id": "vYOLQos8UWRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and install TTS and models"
      ],
      "metadata": {
        "id": "QYauQrJ5crGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/coqui-ai/TTS TTS\n",
        "!pip install -q -e TTS/\n",
        "!pip install -q torchaudio==0.9.0\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "9c2r6SVrTyWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741de4ca-6785-4f0e-dd2d-186e3d3d52a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TTS'...\n",
            "remote: Enumerating objects: 23791, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 23791 (delta 85), reused 93 (delta 52), pack-reused 23600\u001b[K\n",
            "Receiving objects: 100% (23791/23791), 127.81 MiB | 17.23 MiB/s, done.\n",
            "Resolving deltas: 100% (17223/17223), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 284 kB 46.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 26.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 193 kB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 52.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 183 kB 45.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 48.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 124 kB 41.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 487 kB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 67.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 279 kB 48.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 47.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 28.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 21.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 31.4 MB 153 kB/s \n",
            "\u001b[K     |████████████████████████████████| 35.0 MB 397 kB/s \n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 29.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.0 MB 35.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 40.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 18.1 MB 179 kB/s \n",
            "\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-cs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-it (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-nl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-pt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-ru (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-lang-sv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 12.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 25.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 43.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 422 kB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/v0.5.0_models/tts_models--multilingual--multi-dataset--your_tts.zip\n",
        "!unzip tts_models--multilingual--multi-dataset--your_tts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9OQgNm3VUSn",
        "outputId": "a984a5b4-90e7-4ea1-fb91-aded95a52294"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 09:54:51--  https://coqui.gateway.scarf.sh/v0.5.0_models/tts_models--multilingual--multi-dataset--your_tts.zip\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 18.193.247.98, 3.64.83.114\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|18.193.247.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/TTS/releases/download/v0.5.0_models/tts_models--multilingual--multi-dataset--your_tts.zip [following]\n",
            "--2022-02-19 09:54:51--  https://github.com/coqui-ai/TTS/releases/download/v0.5.0_models/tts_models--multilingual--multi-dataset--your_tts.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/265612440/06b726fc-6cd2-4f94-9a17-378b9303dd15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220219T095452Z&X-Amz-Expires=300&X-Amz-Signature=494b9750b9de5ecff83e72387826bfd78a93b7a97e53a6cdf9a62f0cbf823d61&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=265612440&response-content-disposition=attachment%3B%20filename%3Dtts_models--multilingual--multi-dataset--your_tts.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-02-19 09:54:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/265612440/06b726fc-6cd2-4f94-9a17-378b9303dd15?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220219T095452Z&X-Amz-Expires=300&X-Amz-Signature=494b9750b9de5ecff83e72387826bfd78a93b7a97e53a6cdf9a62f0cbf823d61&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=265612440&response-content-disposition=attachment%3B%20filename%3Dtts_models--multilingual--multi-dataset--your_tts.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 394379494 (376M) [application/octet-stream]\n",
            "Saving to: ‘tts_models--multilingual--multi-dataset--your_tts.zip’\n",
            "\n",
            "tts_models--multili 100%[===================>] 376.11M  8.25MB/s    in 39s     \n",
            "\n",
            "2022-02-19 09:55:31 (9.68 MB/s) - ‘tts_models--multilingual--multi-dataset--your_tts.zip’ saved [394379494/394379494]\n",
            "\n",
            "Archive:  tts_models--multilingual--multi-dataset--your_tts.zip\n",
            "   creating: tts_models--multilingual--multi-dataset--your_tts/\n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/config_se.json  \n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/speakers.json  \n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/model_se.pth.tar  \n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/config.json  \n",
            "  inflating: __MACOSX/tts_models--multilingual--multi-dataset--your_tts/._config.json  \n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/model_file.pth.tar  \n",
            "  inflating: tts_models--multilingual--multi-dataset--your_tts/language_ids.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup TTS"
      ],
      "metadata": {
        "id": "DTS9WWJJc18V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# don't ask\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "aSOLXfywwMZv",
        "outputId": "05d949bf-dfa6-4e1b-ffe2-ed145595e109"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.19.5\n",
            "Uninstalling numpy-1.19.5:\n",
            "  Successfully uninstalled numpy-1.19.5\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 10.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "TTS_PATH = \"TTS/\"\n",
        "\n",
        "# add libraries into environment\n",
        "sys.path.append(TTS_PATH) # set this if TTS is not installed globally\n",
        "\n",
        "from TTS.config import load_config\n",
        "from TTS.trainer import Trainer, TrainingArgs\n",
        "from TTS.tts.models.vits import Vits\n",
        "from TTS.tts.utils.speakers import SpeakerManager\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.utils.languages import LanguageManager\n",
        "from TTS.tts.utils.synthesis import synthesis"
      ],
      "metadata": {
        "id": "WbV5n-S0PbmI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "OUT_PATH = \"/content/output\"\n",
        "\n",
        "parent = \"/content/tts_models--multilingual--multi-dataset--your_tts\"\n",
        "# model vars \n",
        "MODEL_PATH = f\"{parent}/model_file.pth.tar\"\n",
        "CONFIG_PATH = f\"{parent}/config.json\"\n",
        "TTS_LANGUAGES = f\"{parent}/language_ids.json\"\n",
        "TTS_SPEAKERS = \"/content/speakers.json\"\n",
        "CONFIG_SE_PATH = f\"{parent}/config_se.json\"\n",
        "CHECKPOINT_SE_PATH = f\"{parent}/model_se.pth.tar\"\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "023Bz9ChXpt6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the config\n",
        "C = load_config(CONFIG_PATH)\n",
        "\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**C.audio, verbose=False)\n",
        "C.output_path = OUT_PATH\n",
        "C.use_language_weighted_sampler = False\n",
        "\n",
        "C.test_sentences = []\n",
        "C.min_seq_len=0\n",
        "C.max_seq_len=500000\n",
        "\n",
        "speaker_manager = SpeakerManager(\n",
        "    encoder_model_path=CHECKPOINT_SE_PATH, \n",
        "    encoder_config_path=CONFIG_SE_PATH,\n",
        "    use_cuda=USE_CUDA)\n",
        "language_manager = LanguageManager()\n",
        "language_manager.set_language_ids_from_config(C)"
      ],
      "metadata": {
        "id": "QFTsKHzmhsu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09bf98d-0d54-4cef-f166-85bb6cde866b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:16000\n",
            " | > resample:False\n",
            " | > num_mels:64\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:512\n",
            " | > power:1.5\n",
            " | > preemphasis:0.97\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:False\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:False\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:True\n",
            " | > db_level:-27.0\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:160\n",
            " | > win_length:400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthesize from d-vectors"
      ],
      "metadata": {
        "id": "z_1TIF305noM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C.model_args.use_speaker_encoder_as_loss = False\n",
        "model = Vits(C, speaker_manager, language_manager)\n",
        "model.load_checkpoint(C, MODEL_PATH, eval=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBwEqPGhDEZ_",
        "outputId": "17926fcc-4cc2-45e5-bd74-988dcc779d28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > initialization of language-embedding layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def synthesis_dvec(text, filepath):\n",
        "  out_path = \"/content/output.wav\"\n",
        "  d_vector = speaker_manager.compute_d_vector_from_clip(filepath)\n",
        "\n",
        "  wav, alignment, _, _ = synthesis(\n",
        "    model,\n",
        "    text,\n",
        "    C,\n",
        "    False,\n",
        "    ap,\n",
        "    speaker_id=None,\n",
        "    d_vector=d_vector,\n",
        "    style_wav=None,\n",
        "    language_id=0,\n",
        "    enable_eos_bos_chars=C.enable_eos_bos_chars,\n",
        "    use_griffin_lim=True,\n",
        "    do_trim_silence=False,\n",
        "    ).values()\n",
        "  ap.save_wav(wav, out_path)\n",
        "  return out_path"
      ],
      "metadata": {
        "id": "4tvWAPkJ5fmi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b8qGgczlpovw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f908fc04-54f7-4672-9b1f-dda8c93deb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Your interface requires microphone or webcam permissions - this may cause issues in Colab. Use the External URL in case of issues.\n",
            "Running on public URL: https://38991.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://38991.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f6ddda39cd0>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f6ddec7dc10>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://38991.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "  synthesis_dvec, \n",
        "  [\"text\", gr.inputs.Audio(source=\"microphone\", type=\"filepath\", label=\"Say anything!\")], \n",
        "  \"audio\",\n",
        "  allow_screenshot=False,\n",
        "  allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune and synthesize"
      ],
      "metadata": {
        "id": "BFtJV-gTljNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.tatoeba.org/exports/per_language/eng/eng_sentences.tsv.bz2\n",
        "!bzip2 -d eng_sentences.tsv.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-p4LUeHv4RV",
        "outputId": "40bdd24c-3bb8-4bb3-bfee-51b27d0dc73e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 09:57:22--  https://downloads.tatoeba.org/exports/per_language/eng/eng_sentences.tsv.bz2\n",
            "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
            "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18158301 (17M) [application/octet-stream]\n",
            "Saving to: ‘eng_sentences.tsv.bz2’\n",
            "\n",
            "eng_sentences.tsv.b 100%[===================>]  17.32M  69.1MB/s    in 0.3s    \n",
            "\n",
            "2022-02-19 09:57:22 (69.1 MB/s) - ‘eng_sentences.tsv.bz2’ saved [18158301/18158301]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "read_tsv = csv.reader(open(\"eng_sentences.tsv\"), delimiter=\"\\t\")\n",
        "sentences = random.sample([t[2] for t in read_tsv if len(t[2]) < 70], 10)"
      ],
      "metadata": {
        "id": "YEQc2T45-aW0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C.use_speaker_embedding = C.model_args.use_speaker_embedding = True\n",
        "C.use_d_vector_file = C.model_args.use_d_vector_file = False\n",
        "C.model_args.speaker_encoder_model_path = C.speaker_encoder_model_path = CHECKPOINT_SE_PATH\n",
        "C.model_args.speaker_encoder_config_path = C.speaker_encoder_config_path = CONFIG_SE_PATH\n",
        "\n",
        "model = Vits(C, speaker_manager, language_manager)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMC315M95z5d",
        "outputId": "4ada251c-c519-4f07-bb56-dba77fe3adf3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > initialization of language-embedding layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def train_and_synth(text, train, epochs, *args):\n",
        "  if train:\n",
        "    C.epochs = epochs\n",
        "    # resample audio\n",
        "    for path in args:\n",
        "      audio, sr = librosa.load(path, 16000)\n",
        "      sf.write(path, audio, sr)\n",
        "\n",
        "    samples = [[sentences[i], p, 'temp', 'en'] for i, p in enumerate(args)]\n",
        "    \n",
        "    trainer = Trainer(\n",
        "      TrainingArgs(restore_path=MODEL_PATH),\n",
        "      C,\n",
        "      OUT_PATH,\n",
        "      model=model,\n",
        "      train_samples=samples[:9],\n",
        "      eval_samples=samples[9:],\n",
        "      training_assets={\"audio_processor\": ap}\n",
        "    )\n",
        "\n",
        "    trainer.fit()\n",
        "\n",
        "  out_path = f\"/content/output.wav\"\n",
        "  \n",
        "  wav, alignment, _, _ = synthesis(\n",
        "    model,\n",
        "    text,\n",
        "    C,\n",
        "    USE_CUDA,\n",
        "    ap,\n",
        "    speaker_id=None,\n",
        "    style_wav=None,\n",
        "    language_id=0,\n",
        "    enable_eos_bos_chars=C.enable_eos_bos_chars,\n",
        "    use_griffin_lim=True,\n",
        "    do_trim_silence=False,\n",
        "  ).values()\n",
        "  ap.save_wav(wav, out_path)\n",
        "  return out_path"
      ],
      "metadata": {
        "id": "nEz1iFqgbZbF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "  train_and_synth, \n",
        "  [\"text\", \"checkbox\", gr.inputs.Slider(0, 1000, 1, 150)] +\n",
        "  [gr.inputs.Audio(source=\"microphone\", type=\"filepath\", label=s, optional=False) for s in sentences], \n",
        "  \"audio\",\n",
        "  allow_screenshot=False,\n",
        "  allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "TJb2MmDGUaq2",
        "outputId": "e6020ba2-dc5f-46f7-aebf-b63e43681c8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Your interface requires microphone or webcam permissions - this may cause issues in Colab. Use the External URL in case of issues.\n",
            "Running on public URL: https://58934.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://58934.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f6dd770f850>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f6ddec7dc10>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://58934.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Zeroshot-w-Gradio.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "z_1TIF305noM"
      ],
      "authorship_tag": "ABX9TyOEbnvtW7ZfsHkXFKagTqhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}